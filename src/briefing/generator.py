"""Briefing generator for daily, weekly, and monthly summaries.

Queries Zilliz Cloud for recent Dropbox file changes and email activity,
searches for schedule/task-related keywords, and uses the Gemini LLM to
produce a structured Korean briefing with separate sections for files,
emails, and upcoming tasks.
"""

from __future__ import annotations

import logging
from datetime import datetime, timedelta, timezone
from typing import Any

from src.db.zilliz_client import get_client
from src.rag.retriever import Retriever
from src.rag.generator import Generator

logger = logging.getLogger(__name__)

# ------------------------------------------------------------------
# Constants
# ------------------------------------------------------------------

_TYPE_LABELS: dict[str, str] = {
    "daily": "ì¼ê°„",
    "weekly": "ì£¼ê°„",
    "monthly": "ì›”ê°„",
}

# DnS staff email addresses (used to distinguish sent vs received)
_DNS_STAFF_EMAILS: set[str] = {
    "theking57@naver.com",
    "ruthkim2015@naver.com",
}

_TASK_KEYWORDS: list[str] = [
    "ì¼ì •",
    "ë§ˆê°",
    "deadline",
    "íšŒì˜",
    "ë¯¸íŒ…",
    "ì˜ˆì •",
    "ë‚©ê¸°",
    "ë‚©í’ˆ",
    "ê²€ìˆ˜",
    "ê³„ì•½",
    "ìž…ì°°",
    "ì œì¶œ",
    "ë³´ê³ ",
    "ì™„ë£Œ ì˜ˆì •",
    "ì§„í–‰ ì¤‘",
    "pending",
]

_KST = timezone(timedelta(hours=9))

# ------------------------------------------------------------------
# Prompt templates (daily vs weekly/monthly)
# ------------------------------------------------------------------

_DAILY_PROMPT = """\
ë‹¤ìŒì€ ìµœê·¼ ì—…ë¬´ í™œë™ ë°ì´í„°ìž…ë‹ˆë‹¤.

== ìµœê·¼ ë³€ë™ëœ íŒŒì¼ ({file_count}ê±´) ==
{files_section}

== ë°›ì€ ë©”ì¼ ({received_count}ê±´) ==
{received_section}

== ë³´ë‚¸ ë©”ì¼ ({sent_count}ê±´) ==
{sent_section}

== ì—…ë¬´/ì¼ì • ê´€ë ¨ ë¬¸ì„œ ({task_count}ê±´) ==
{tasks_section}

ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¼ê°„ ì—…ë¬´ ë¸Œë¦¬í•‘ì„ ìž‘ì„±í•˜ì„¸ìš”:

ðŸ“‹ ì¼ê°„ ì—…ë¬´ ë¸Œë¦¬í•‘ ({date})

[íŒŒì¼ ë³€ë™ ì‚¬í•­]
â€¢ ìƒˆë¡œ ì¶”ê°€/ìˆ˜ì •ëœ íŒŒì¼ê³¼ ì£¼ìš” ë‚´ìš© ìš”ì•½

[ë°›ì€ ë©”ì¼ ìš”ì•½]
â€¢ ì™¸ë¶€ì—ì„œ ìˆ˜ì‹ í•œ ì£¼ìš” ë©”ì¼ì˜ í•µì‹¬ ë‚´ìš©

[ë³´ë‚¸ ë©”ì¼ ìš”ì•½]
â€¢ DnS ì§ì›ì´ ë°œì‹ í•œ ì£¼ìš” ë©”ì¼ì˜ í•µì‹¬ ë‚´ìš©

[ì˜¤ëŠ˜ì˜ í•  ì¼]
âš ï¸ ë§ˆê° ìž„ë°• í•­ëª©
â€¢ ì˜ˆì •ëœ ì—…ë¬´ ëª©ë¡

[ì°¸ê³ ì‚¬í•­]
â€¢ ê¸°íƒ€ ì¤‘ìš” ì‚¬í•­

ê·œì¹™:
- ë°ì´í„°ê°€ ì—†ëŠ” ì„¹ì…˜ì€ "í•´ë‹¹ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œ
- 900ìž ì´ë‚´ë¡œ ìž‘ì„±
- í•œêµ­ì–´ë¡œ ìž‘ì„±"""

_WEEKLY_PROMPT = """\
ë‹¤ìŒì€ ì§€ë‚œ í•œ ì£¼ê°„ì˜ ì—…ë¬´ í™œë™ ë°ì´í„°ìž…ë‹ˆë‹¤.

== ì´ë²ˆ ì£¼ ë³€ë™ëœ íŒŒì¼ ({file_count}ê±´) ==
{files_section}

== ì´ë²ˆ ì£¼ ë°›ì€ ë©”ì¼ ({received_count}ê±´) ==
{received_section}

== ì´ë²ˆ ì£¼ ë³´ë‚¸ ë©”ì¼ ({sent_count}ê±´) ==
{sent_section}

== ì—…ë¬´/ì¼ì • ê´€ë ¨ ë¬¸ì„œ ({task_count}ê±´) ==
{tasks_section}

ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì£¼ê°„ ì—…ë¬´ ë¸Œë¦¬í•‘ì„ ìž‘ì„±í•˜ì„¸ìš”:

ðŸ“‹ ì£¼ê°„ ì—…ë¬´ ë¸Œë¦¬í•‘ ({date})

[ì´ë²ˆ ì£¼ ì£¼ìš” í™œë™]
â€¢ ì£¼ìš” íŒŒì¼ ìž‘ì—… ë° ë©”ì¼ í™œë™ ìš”ì•½ (3~5ê°œ)

[ë°›ì€ ë©”ì¼ ìš”ì•½]
â€¢ ì™¸ë¶€ì—ì„œ ìˆ˜ì‹ í•œ ì£¼ìš” ë©”ì¼ì˜ í•µì‹¬ ë‚´ìš©

[ë³´ë‚¸ ë©”ì¼ ìš”ì•½]
â€¢ DnS ì§ì›ì´ ë°œì‹ í•œ ì£¼ìš” ë©”ì¼ì˜ í•µì‹¬ ë‚´ìš©

[í”„ë¡œì íŠ¸ë³„ ì§„í–‰ ìƒí™©]
â€¢ í”„ë¡œì íŠ¸/ê³„ì•½ ë‹¨ìœ„ë¡œ ì§„í–‰ ìƒí™© ì •ë¦¬

[ë‹¤ìŒ ì£¼ ì˜ˆì • ì—…ë¬´]
âš ï¸ ë§ˆê° ìž„ë°• í•­ëª©
â€¢ ì˜ˆì •ëœ ì—…ë¬´ ëª©ë¡

[ì°¸ê³ ì‚¬í•­]
â€¢ ê¸°íƒ€ ì¤‘ìš” ì‚¬í•­

ê·œì¹™:
- ë°ì´í„°ê°€ ì—†ëŠ” ì„¹ì…˜ì€ "í•´ë‹¹ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œ
- 900ìž ì´ë‚´ë¡œ ìž‘ì„±
- í•œêµ­ì–´ë¡œ ìž‘ì„±"""

_MONTHLY_PROMPT = """\
ë‹¤ìŒì€ ì§€ë‚œ í•œ ë‹¬ê°„ì˜ ì—…ë¬´ í™œë™ ë°ì´í„°ìž…ë‹ˆë‹¤.

== ì´ë²ˆ ë‹¬ ë³€ë™ëœ íŒŒì¼ ({file_count}ê±´) ==
{files_section}

== ì´ë²ˆ ë‹¬ ë°›ì€ ë©”ì¼ ({received_count}ê±´) ==
{received_section}

== ì´ë²ˆ ë‹¬ ë³´ë‚¸ ë©”ì¼ ({sent_count}ê±´) ==
{sent_section}

== ì—…ë¬´/ì¼ì • ê´€ë ¨ ë¬¸ì„œ ({task_count}ê±´) ==
{tasks_section}

ìœ„ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì›”ê°„ ì—…ë¬´ ë¸Œë¦¬í•‘ì„ ìž‘ì„±í•˜ì„¸ìš”:

ðŸ“‹ ì›”ê°„ ì—…ë¬´ ë¸Œë¦¬í•‘ ({date})

[ì´ë²ˆ ë‹¬ ì£¼ìš” ì„±ê³¼]
â€¢ ì™„ë£Œëœ ì£¼ìš” ì—…ë¬´ (3~5ê°œ)

[ë°›ì€ ë©”ì¼ ìš”ì•½]
â€¢ ì™¸ë¶€ì—ì„œ ìˆ˜ì‹ í•œ ì£¼ìš” ë©”ì¼ì˜ í•µì‹¬ ë‚´ìš©

[ë³´ë‚¸ ë©”ì¼ ìš”ì•½]
â€¢ DnS ì§ì›ì´ ë°œì‹ í•œ ì£¼ìš” ë©”ì¼ì˜ í•µì‹¬ ë‚´ìš©

[í”„ë¡œì íŠ¸ë³„ ì§„í–‰ í˜„í™©]
â€¢ í”„ë¡œì íŠ¸/ê³„ì•½ ë‹¨ìœ„ í˜„í™© ì •ë¦¬

[ë‹¤ìŒ ë‹¬ ì£¼ìš” ì¼ì •]
âš ï¸ ë§ˆê° ìž„ë°• í•­ëª©
â€¢ ì˜ˆì •ëœ ì—…ë¬´ ë° ë§ˆê° ì¼ì •

[ì°¸ê³ ì‚¬í•­]
â€¢ ê¸°íƒ€ ì¤‘ìš” ì‚¬í•­

ê·œì¹™:
- ë°ì´í„°ê°€ ì—†ëŠ” ì„¹ì…˜ì€ "í•´ë‹¹ ì—†ìŒ"ìœ¼ë¡œ í‘œì‹œ
- 900ìž ì´ë‚´ë¡œ ìž‘ì„±
- í•œêµ­ì–´ë¡œ ìž‘ì„±"""

_PROMPTS: dict[str, str] = {
    "daily": _DAILY_PROMPT,
    "weekly": _WEEKLY_PROMPT,
    "monthly": _MONTHLY_PROMPT,
}


# ------------------------------------------------------------------
# BriefingGenerator
# ------------------------------------------------------------------


class BriefingGenerator:
    """Generate periodic business briefings from indexed documents."""

    def __init__(self) -> None:
        self.retriever = Retriever()
        self.generator = Generator()
        self.client = get_client()

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------

    async def generate(self, briefing_type: str = "daily") -> str:
        """Generate a briefing for the given period type.

        Parameters
        ----------
        briefing_type:
            One of ``"daily"``, ``"weekly"``, or ``"monthly"``.

        Returns
        -------
        str
            The generated briefing text.
        """
        if briefing_type not in _TYPE_LABELS:
            raise ValueError(
                f"Invalid briefing_type '{briefing_type}'. "
                f"Must be one of {list(_TYPE_LABELS.keys())}."
            )

        start, end = self._get_date_range(briefing_type)
        logger.info(
            "Generating %s briefing for %s ~ %s",
            briefing_type,
            start.isoformat(),
            end.isoformat(),
        )

        # Collect data in categories
        data = self._collect_briefing_data(briefing_type, start, end)

        has_data = (
            data["recent_files"]
            or data["received_emails"]
            or data["sent_emails"]
            or data["upcoming_tasks"]
        )
        if not has_data:
            msg = "í•´ë‹¹ ê¸°ê°„ì— ìƒˆë¡œìš´ ë¬¸ì„œ/ë©”ì¼ì´ ì—†ìŠµë‹ˆë‹¤."
            logger.info(msg)
            self._save_briefing(briefing_type, msg)
            return msg

        # Build the LLM prompt
        now_kst = datetime.now(_KST)
        prompt = self._build_prompt(briefing_type, data, now_kst)

        # Call the LLM with briefing-specific settings
        briefing_system = (
            "ë‹¹ì‹ ì€ ì—…ë¬´ ë¸Œë¦¬í•‘ì„ ìž‘ì„±í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤. "
            "ì œê³µëœ íŒŒì¼ ë³€ë™ ì‚¬í•­ê³¼ ì´ë©”ì¼ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ "
            "êµ¬ì¡°í™”ëœ í•œêµ­ì–´ ì—…ë¬´ ë¸Œë¦¬í•‘ì„ ìž‘ì„±í•˜ì„¸ìš”. "
            "ëª¨ë“  ì„¹ì…˜ì„ ë¹ ì§ì—†ì´ ìž‘ì„±í•˜ê³ , 900ìž ì´ë‚´ë¡œ ì™„ì„±í•˜ì„¸ìš”."
        )
        try:
            content = await self.generator._call_with_fallback(
                prompt,
                system_instruction=briefing_system,
                max_output_tokens=2048,
            )
        except Exception:
            logger.exception("Failed to generate briefing via LLM")
            content = "ë¸Œë¦¬í•‘ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”."

        # Persist
        self._save_briefing(briefing_type, content)

        logger.info(
            "%s briefing generated (%d chars)", briefing_type, len(content)
        )
        return content

    # ------------------------------------------------------------------
    # Data collection
    # ------------------------------------------------------------------

    def _collect_briefing_data(
        self,
        briefing_type: str,
        start: datetime,
        end: datetime,
    ) -> dict[str, list[dict[str, Any]]]:
        """Collect documents, emails, and task-related items for the briefing."""
        start_iso = start.isoformat()
        end_iso = end.isoformat()

        file_limit = 15 if briefing_type == "daily" else 30
        email_limit = 30 if briefing_type == "daily" else 60

        # 1. Recently changed Dropbox files (by updated_date = indexing time)
        recent_files = self.retriever.search_by_date_range(
            date_field="updated_date",
            start_date=start_iso,
            end_date=end_iso,
            source_type="dropbox",
            limit=file_limit,
        )

        # 2. Recent emails (by created_date = email date)
        all_emails = self.retriever.search_by_date_range(
            date_field="created_date",
            start_date=start_iso,
            end_date=end_iso,
            source_type="email",
            limit=email_limit,
        )

        # Split into received vs sent based on DnS staff addresses
        received_emails: list[dict[str, Any]] = []
        sent_emails: list[dict[str, Any]] = []
        for email in all_emails:
            sender = (email.get("email_from") or "").lower().strip()
            if sender in _DNS_STAFF_EMAILS:
                sent_emails.append(email)
            else:
                received_emails.append(email)

        # 3. Upcoming tasks / schedule-related (vector search)
        upcoming_tasks = self._search_upcoming_tasks(start_iso)

        return {
            "recent_files": recent_files,
            "received_emails": received_emails,
            "sent_emails": sent_emails,
            "upcoming_tasks": upcoming_tasks,
        }

    def _search_upcoming_tasks(
        self,
        after_date: str,
    ) -> list[dict[str, Any]]:
        """Search for schedule/task-related documents via vector similarity.

        Uses an expanded set of keywords and deduplicates results.
        """
        all_results: list[dict[str, Any]] = []

        for keyword in _TASK_KEYWORDS:
            try:
                results = self.retriever.search(
                    query=keyword,
                    after_date=after_date,
                    top_k=3,
                )
                all_results.extend(results)
            except Exception:
                logger.warning(
                    "Task keyword search failed for '%s'",
                    keyword,
                    exc_info=True,
                )

        # Deduplicate
        unique = self._deduplicate(all_results)

        logger.info(
            "Task keyword search: %d raw -> %d unique results",
            len(all_results),
            len(unique),
        )
        return unique[:15]

    # ------------------------------------------------------------------
    # Prompt building
    # ------------------------------------------------------------------

    def _build_prompt(
        self,
        briefing_type: str,
        data: dict[str, list[dict[str, Any]]],
        now_kst: datetime,
    ) -> str:
        """Build the LLM prompt with separated file/email/task sections."""
        files_section = self._format_files(data["recent_files"])
        received_section = self._format_emails(data["received_emails"], label="ë°›ì€")
        sent_section = self._format_emails(data["sent_emails"], label="ë³´ë‚¸")
        tasks_section = self._format_tasks(data["upcoming_tasks"])

        template = _PROMPTS[briefing_type]
        return template.format(
            file_count=len(data["recent_files"]),
            files_section=files_section,
            received_count=len(data["received_emails"]),
            received_section=received_section,
            sent_count=len(data["sent_emails"]),
            sent_section=sent_section,
            task_count=len(data["upcoming_tasks"]),
            tasks_section=tasks_section,
            date=now_kst.strftime("%Y-%m-%d %a"),
        )

    # ------------------------------------------------------------------
    # Formatting helpers
    # ------------------------------------------------------------------

    @staticmethod
    def _format_files(docs: list[dict[str, Any]]) -> str:
        """Format Dropbox files as 'filename (folder) - date'."""
        if not docs:
            return "(ë³€ë™ëœ íŒŒì¼ ì—†ìŒ)"

        parts: list[str] = []
        for idx, doc in enumerate(docs, start=1):
            filename = doc.get("filename") or "ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼"
            folder = doc.get("folder_path") or ""
            if folder:
                folder = folder.strip("/")
            created = str(doc.get("created_date", ""))[:10]
            content = (doc.get("content") or "").strip()
            if len(content) > 150:
                content = content[:150] + "..."

            line = f"{idx}. [{filename}]"
            if folder:
                line += f" ({folder})"
            if created:
                line += f" - {created}"
            if content:
                line += f"\n   {content}"
            parts.append(line)

        return "\n\n".join(parts)

    @staticmethod
    def _format_emails(docs: list[dict[str, Any]], label: str = "") -> str:
        """Format emails as '[subject] from sender - date'."""
        if not docs:
            return f"({label} ë©”ì¼ ì—†ìŒ)" if label else "(ë©”ì¼ ì—†ìŒ)"

        parts: list[str] = []
        for idx, doc in enumerate(docs, start=1):
            subject = doc.get("email_subject") or "ì œëª© ì—†ìŒ"
            sender = doc.get("email_from") or ""
            email_date = str(doc.get("email_date") or doc.get("created_date") or "")[:10]
            content = (doc.get("content") or "").strip()
            if len(content) > 150:
                content = content[:150] + "..."

            line = f"{idx}. [{subject}]"
            if sender:
                line += f" ë°œì‹ : {sender}"
            if email_date:
                line += f" ({email_date})"
            if content:
                line += f"\n   {content}"
            parts.append(line)

        return "\n\n".join(parts)

    @staticmethod
    def _format_tasks(docs: list[dict[str, Any]]) -> str:
        """Format task/schedule-related documents with content excerpts."""
        if not docs:
            return "(ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ)"

        parts: list[str] = []
        for idx, doc in enumerate(docs, start=1):
            source_type = doc.get("source_type", "")
            content = (doc.get("content") or "").strip()
            if len(content) > 200:
                content = content[:200] + "..."

            if source_type == "dropbox":
                label = doc.get("filename") or "íŒŒì¼"
                source_label = f"[íŒŒì¼: {label}]"
            elif source_type == "email":
                subject = doc.get("email_subject") or "ì œëª© ì—†ìŒ"
                sender = doc.get("email_from") or ""
                source_label = f"[ì´ë©”ì¼: {subject} - {sender}]"
            else:
                source_label = f"[{source_type}]"

            created = str(doc.get("created_date", ""))[:10]
            date_part = f" ({created})" if created else ""

            parts.append(f"{idx}. {source_label}{date_part}\n   {content}")

        return "\n\n".join(parts)

    # ------------------------------------------------------------------
    # Deduplication
    # ------------------------------------------------------------------

    @staticmethod
    def _deduplicate(docs: list[dict[str, Any]]) -> list[dict[str, Any]]:
        """Remove duplicate documents based on ``id`` or content prefix."""
        seen: set[str] = set()
        unique: list[dict[str, Any]] = []

        for doc in docs:
            doc_id = doc.get("id")
            if doc_id is not None:
                key = f"id:{doc_id}"
            else:
                content = doc.get("content", "")
                key = f"content:{content[:50]}"

            if key in seen:
                continue
            seen.add(key)
            unique.append(doc)

        return unique

    # ------------------------------------------------------------------
    # Date range
    # ------------------------------------------------------------------

    @staticmethod
    def _get_date_range(briefing_type: str) -> tuple[datetime, datetime]:
        """Return ``(start, end)`` datetimes in KST for the given type."""
        now = datetime.now(_KST)

        if briefing_type == "daily":
            start = now - timedelta(days=1)
        elif briefing_type == "weekly":
            start = now - timedelta(days=7)
        elif briefing_type == "monthly":
            start = now - timedelta(days=30)
        else:
            start = now - timedelta(days=1)

        return start, now

    # ------------------------------------------------------------------
    # Persistence
    # ------------------------------------------------------------------

    def _save_briefing(self, briefing_type: str, content: str) -> None:
        """Insert the generated briefing into the ``briefings`` collection."""
        now = datetime.now(timezone.utc).isoformat()
        try:
            self.client.insert(
                collection_name="briefings",
                data=[{
                    "briefing_type": briefing_type,
                    "content": content[:10000],
                    "generated_at": now,
                    "sent": False,
                    "_dummy_vec": [0.0, 0.0],
                }],
            )
            logger.info("Briefing saved to database (type=%s)", briefing_type)
        except Exception:
            logger.exception(
                "Failed to save briefing to database (type=%s)", briefing_type
            )
